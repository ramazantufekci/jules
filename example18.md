SÃ¼per ğŸ‘ ÅŸimdi sÄ±radaki parÃ§ayÄ± ekleyelim: **Observability (deploy sonrasÄ± log toplanmasÄ±)**.

Åu an kurallarÄ± deploy ediyoruz, restart ediyoruz ama:

* `wazuh-manager` gerÃ§ekten dÃ¼zgÃ¼n baÅŸladÄ± mÄ±?
* XML veya rule hatalarÄ± var mÄ±?
* Deploy sonrasÄ± uyarÄ±lar loglarda gÃ¶zÃ¼kÃ¼yor mu?

bunlarÄ± CI/CD Ã§Ä±ktÄ±sÄ±na taÅŸÄ±madÄ±k. Bunun iÃ§in **log toplama & artifact** mekanizmasÄ± kuralÄ±m.

---

# ğŸ” Deploy SonrasÄ± Log Toplama

## 1. Deploy Workflowâ€™a Ek AdÄ±m (Her Host Ä°Ã§in)

`deploy_rules.yml` iÃ§ine (canary ve cluster deploy jobâ€™larÄ±na) eklenebilir:

```yaml
      - name: Collect wazuh-manager logs on ${{ matrix.host }}
        uses: appleboy/ssh-action@v1.1.0
        with:
          host: ${{ matrix.host }}
          username: ${{ secrets.WAZUH_SERVER_USER }}
          key: ${{ secrets.WAZUH_SERVER_SSH_KEY }}
          port: ${{ secrets.WAZUH_SSH_PORT }}
          script: |
            echo "ğŸ“œ Collecting logs from wazuh-manager..."
            sudo journalctl -u wazuh-manager --since "-2m" --no-pager > /tmp/wazuh_${{ matrix.host }}.log
        continue-on-error: true

      - name: Copy logs as artifact
        uses: actions/upload-artifact@v4
        with:
          name: wazuh-logs-${{ matrix.host }}
          path: /tmp/wazuh_${{ matrix.host }}.log
```

---

## 2. Canary Job Ä°Ã§in Benzer Ek

```yaml
      - name: Collect wazuh-manager logs (canary)
        uses: appleboy/ssh-action@v1.1.0
        with:
          host: ${{ secrets.WAZUH_CANARY_HOST }}
          username: ${{ secrets.WAZUH_SERVER_USER }}
          key: ${{ secrets.WAZUH_SERVER_SSH_KEY }}
          port: ${{ secrets.WAZUH_SSH_PORT }}
          script: |
            echo "ğŸ“œ Collecting canary logs..."
            sudo journalctl -u wazuh-manager --since "-2m" --no-pager > /tmp/wazuh_canary.log
        continue-on-error: true

      - name: Upload Canary Logs
        uses: actions/upload-artifact@v4
        with:
          name: wazuh-logs-canary
          path: /tmp/wazuh_canary.log
```

---

## 3. SonuÃ§

* Deploy sonrasÄ± her sunucunun son **2 dakikalÄ±k `wazuh-manager` loglarÄ±** pipeline artifact olarak saklanÄ±yor.
* EÄŸer deployment baÅŸarÄ±sÄ±z olursa ya da manager loglarÄ±nda hata varsa â†’ CI/CD pipeline Ã§Ä±ktÄ±sÄ±ndan direkt indirip inceleyebilirsin.
* SOC ekibi geÃ§miÅŸ deploy loglarÄ±nÄ± pipeline runâ€™larÄ±ndan indirebilir.

---

## 4. Ä°leri Seviye GeliÅŸtirme

* **Log Parsing**: CI pipeline loglarÄ±nÄ± parse edip belirli keywordâ€™ler (`ERROR`, `Invalid decoder`, `Invalid rule`) bulunduÄŸunda job fail etsin.
* **Centralized Observability**: Artifact olarak saklamanÄ±n Ã¶tesinde, deploy loglarÄ± **ELK / Grafana Loki / S3** gibi merkezi bir yere gÃ¶nderilebilir.
* **Alerting**: EÄŸer loglarda hata varsa Slack/Teams bildirimi gÃ¶nderilebilir.

---

âœ… BÃ¶ylece artÄ±k pipeline sadece deploy etmiyor, aynÄ± zamanda **deploy sonrasÄ± doÄŸrulama loglarÄ±nÄ±** topluyor â†’ gerÃ§ek bir **observability** katmanÄ± eklenmiÅŸ oluyor.

---

ğŸ‘‰ Ä°stersen ben sana bir de **log parsing + otomatik fail mekanizmasÄ±** ekleyeyim mi (Ã¶r. loglarda â€œERRORâ€ gÃ¶rÃ¼nÃ¼rse pipeline direkt dursun)?
