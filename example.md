Harika ğŸ™Œ O zaman sana restoran SEO iÃ§erik Ã¼retici iÃ§in **Ã¶rnek FastAPI + LangChain backend** kodunu hazÄ±rlÄ±yorum. Bu servis, n8nâ€™in Ã§aÄŸÄ±racaÄŸÄ± `/generate_content` endpointâ€™ini barÄ±ndÄ±racak.

---

# ğŸ› ï¸ FastAPI + LangChain Backend (Ã¶rnek)

```python
from fastapi import FastAPI
from pydantic import BaseModel
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA

# --- FastAPI app ---
app = FastAPI()

# --- Config ---
CHROMA_DB_DIR = "./chroma_db"
MODEL_NAME = "gpt-3.5-turbo"   # dÃ¼ÅŸÃ¼k maliyet iÃ§in
embeddings = OpenAIEmbeddings()

# --- VektÃ¶r veritabanÄ± ---
vectorstore = Chroma(
    persist_directory=CHROMA_DB_DIR,
    embedding_function=embeddings
)

retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
llm = ChatOpenAI(model=MODEL_NAME, temperature=0.7)

# --- Prompt ÅŸablonu ---
TEMPLATE = """
Sen bir restoran iÃ§in SEO uyumlu iÃ§erik Ã¼reten bir yazarsÄ±n.

Restoran adÄ±: {restaurant}
Anahtar kelime: {keyword}
KullanÄ±lacak bilgiler (menÃ¼/Ã¶zellikler): {context}

LÃ¼tfen SEO uyumlu bir {content_type} yazÄ±sÄ± Ã¼ret.
Metin akÄ±cÄ±, ikna edici ve kullanÄ±cÄ±yÄ± restorana yÃ¶nlendiren bir Ã¼slup taÅŸÄ±malÄ±.
"""

prompt = PromptTemplate(
    template=TEMPLATE,
    input_variables=["restaurant", "keyword", "context", "content_type"]
)

# --- API giriÅŸ modeli ---
class ContentRequest(BaseModel):
    keyword: str
    content_type: str  # blog, social_post, google_business
    restaurant: str

# --- Endpoint ---
@app.post("/generate_content")
def generate_content(req: ContentRequest):
    # ilgili bilgileri Chroma'dan getir
    docs = retriever.get_relevant_documents(req.keyword)
    context = "\n".join([d.page_content for d in docs])

    # prompt doldur
    final_prompt = prompt.format(
        restaurant=req.restaurant,
        keyword=req.keyword,
        context=context,
        content_type=req.content_type
    )

    # modelden yanÄ±t al
    result = llm.predict(final_prompt)

    return {"content": result}
```

---

# âš™ï¸ Ã‡alÄ±ÅŸtÄ±rma

1. DosyayÄ± `app.py` olarak kaydet.
2. FastAPIâ€™yi Ã§alÄ±ÅŸtÄ±r:

   ```bash
   uvicorn app:app --reload --port 8000
   ```
3. n8nâ€™den ÅŸu endpointâ€™e POST isteÄŸi gÃ¶nder:

   ```
   http://localhost:8000/generate_content
   ```

   Body Ã¶rneÄŸi:

   ```json
   {
     "keyword": "Ankara kahvaltÄ± mekanÄ±",
     "content_type": "blog",
     "restaurant": "X Restoran"
   }
   ```

---

# âœ… Ã–rnek YanÄ±t

```json
{
  "content": "Ankaraâ€™da kahvaltÄ± keyfi iÃ§in en doÄŸru adreslerden biri X Restoran. Serpme kahvaltÄ± menÃ¼mÃ¼z..."
}
```

---

ğŸ’¡ Bu backendâ€™i n8n **HTTP Request node** Ã¼zerinden kolayca Ã§aÄŸÄ±rabilirsin. Ã‡Ä±ktÄ±yÄ± Google Docsâ€™a ya da Instagram APIâ€™sine gÃ¶nderip zinciri tamamlamÄ±ÅŸ olursun.

---

ğŸ‘‰ Ä°stersen sana bunun iÃ§in bir de **Chroma DBâ€™ye restoran menÃ¼sÃ¼nÃ¼ yÃ¼kleme scripti (Ã¶rnek Python kodu)** yazayÄ±m mÄ±? BÃ¶ylece menÃ¼yÃ¼ Ã¶nceden vektÃ¶r veritabanÄ±na ekleyip iÃ§erik Ã¼retiminde kullanabilirsin.
